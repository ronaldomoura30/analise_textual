{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.naive_bayes import MultinomialNB      \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lendo o arquivo csv com o pandas\n",
    "df = pd.read_csv('./dados/site_alura.csv', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Separando as colunas do csv entre:\n",
    "X = Características do dados\n",
    "Y = Classificação das características \n",
    "\"\"\"\n",
    "\n",
    "X = df[[\"recencia\", \"frequencia\", \"semanas\"]]\n",
    "Y = df[\"situacao\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dummies = pd.get_dummies(X)\n",
    "X = X_dummies.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "porcentagem_treino = 0.6\n",
    "porcentagem_teste = 0.2\n",
    "\n",
    "tamanho_treino = int(porcentagem_treino * len(X))\n",
    "tamanho_teste = int(porcentagem_teste * len(X))\n",
    "tamanho_validacao = len(Y) - (tamanho_treino + tamanho_teste)\n",
    "\n",
    "treino_dados = X[0:tamanho_treino]\n",
    "treino_marcacoes = Y[0: tamanho_treino]\n",
    "\n",
    "fim_dados_teste = tamanho_treino + tamanho_teste\n",
    "teste_dados = X[tamanho_treino:fim_dados_teste]\n",
    "teste_marcacoes = Y[tamanho_treino:fim_dados_teste]\n",
    "\n",
    "validacao_dados = X[fim_dados_teste:]\n",
    "validacao_marcacoes = Y[fim_dados_teste:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho de treino:  135\n",
      "Tamanho de teste:  45\n",
      "Tamanho de validação:  45\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamanho de treino: \", tamanho_treino)\n",
    "print(\"Tamanho de teste: \", tamanho_teste)\n",
    "print(\"Tamanho de validação: \", tamanho_validacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contador:  Counter({1: 36, 2: 6, 0: 3})\n",
      "Taxa de acertos base: 80.00\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Verificando a acuracia do modelo, comparando com modelos burros\"\"\"\n",
    "\n",
    "contador = Counter(teste_marcacoes)\n",
    "taxa_acerto_base = 100.0 * max(Counter(teste_marcacoes).values())/len(teste_marcacoes)\n",
    "\n",
    "print(\"Contador: \", contador)\n",
    "print(\"Taxa de acertos base: {:.2f}\" .format(taxa_acerto_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1º Separação 90% para treino 10% para teste, acuracia 82,00\n",
    "#2º Separação 80% para treino 20% para teste, acuracia 82,00\n",
    "#3º Separação 70% para treino 30% para teste, acuracia 83,66\n",
    "#4º Separação 60% para treino 40% para teste, acuracia 84,25\n",
    "#5º Separação 50% para treino 50% para teste, acuracia 82,19\n",
    "\n",
    "def fit_and_predict(modelo, nome_algoritmo, treino_dados, treino_marcacoes, teste_dados, teste_marcadores):\n",
    "    \"\"\"\n",
    "        Treinando e predizendo o modelo\n",
    "        Verificando a acuracia do modelo\n",
    "        resultado = São as inferencias que o modelo predice tendo por base o as caracteristicas e resultados passados \n",
    "        no treino marcacoes_teste = São os resultados esperados para os dados enviados para predição\n",
    "    \"\"\"\n",
    "    modelo.fit(treino_dados, treino_marcacoes)\n",
    "\n",
    "    resultado = modelo.predict(teste_dados)\n",
    "\n",
    "    diferencas = (resultado == teste_marcacoes)\n",
    "\n",
    "    acertos = sum(diferencas)\n",
    "    taxa_acertos = 100 * (acertos / len(teste_dados))\n",
    "                          \n",
    "    print(\"Taxa de acertos para algoritmo {}, é de: {:.2f}\" .format(nome_algoritmo, taxa_acertos))\n",
    "    return taxa_acertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict_dados_reais(modelo, treino_dados, treino_marcacoes, validacao_dados, validacao_marcacoes):\n",
    "    \"\"\"\n",
    "        Treinando e predizendo o modelo\n",
    "        Verificando a acuracia do modelo\n",
    "        resultado = São as inferencias que o modelo predice tendo por base o as caracteristicas e resultados passados \n",
    "        no treino marcacoes_teste = São os resultados esperados para os dados enviados para predição\n",
    "    \"\"\"\n",
    "    modelo.fit(treino_dados, treino_marcacoes)\n",
    "    \n",
    "    resultado = modelo.predict(validacao_dados)\n",
    "\n",
    "    diferencas = (resultado == validacao_marcacoes)\n",
    "\n",
    "    acertos = sum(diferencas)\n",
    "    print(\"Taxa de acertos para algoritmo real, é de: {:.2f}\" .format(100 * (acertos / len(validacao_dados))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acertos base: 80.00\n",
      "Taxa de acertos para algoritmo MultinomialNB, é de: 88.89\n",
      "Taxa de acertos para algoritmo AdaBoostClassifier, é de: 80.00\n",
      "Taxa de acertos para algoritmo OneVersusRest, é de: 93.33\n",
      "Taxa de acertos para algoritmo OneVersusOne, é de: 100.00\n",
      "Taxa de acertos para algoritmo real, é de: 100.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Criando quatro modelos: MultinomialNB, AdaBoostClassifier, OneVersusRest, OneVersusOne\n",
    "\n",
    "Obs.: De maneira geral a previsão dos algoritmos funcionam identificando e classificando os elementos por meio\n",
    "das características que foram passadas no treinamento.\n",
    "Obs.1: Se a performance não for problema o algoritmo OneVersusOne deve ser executado.\n",
    "\"\"\"\n",
    "resultados = {}\n",
    "print(\"Taxa de acertos base: {:.2f}\" .format(taxa_acerto_base))\n",
    "\n",
    "modelo_multinomial = MultinomialNB()\n",
    "resultado_multinomial = fit_and_predict(modelo_multinomial, \"MultinomialNB\", treino_dados, treino_marcacoes,\n",
    "                                        teste_dados, teste_marcacoes)\n",
    "resultados[resultado_multinomial] = modelo_multinomial\n",
    "\n",
    "modelo_adaBoostClassifier = AdaBoostClassifier()\n",
    "resultado_adaboost = fit_and_predict(modelo_adaBoostClassifier, \"AdaBoostClassifier\", treino_dados, treino_marcacoes,\n",
    "                                     teste_dados, teste_marcacoes)\n",
    "resultados[resultado_adaboost] = modelo_adaBoostClassifier\n",
    "\n",
    "modelo_OneVersusRest = OneVsRestClassifier(LinearSVC(random_state=0))\n",
    "resultado_OneVersusRest = fit_and_predict(modelo_OneVersusRest, \"OneVersusRest\", treino_dados, treino_marcacoes,\n",
    "                                          teste_dados, teste_marcacoes)\n",
    "resultados[resultado_OneVersusRest] = modelo_OneVersusRest\n",
    "\n",
    "modelo_OneVersusOne = OneVsOneClassifier(LinearSVC(random_state=0))\n",
    "resultado_OneVersusOne = fit_and_predict(modelo_OneVersusOne, \"OneVersusOne\", treino_dados, treino_marcacoes,\n",
    "                                          teste_dados, teste_marcacoes)\n",
    "resultados[resultado_OneVersusOne] = modelo_OneVersusOne\n",
    "\n",
    "vencedor = resultados[max(resultados)]\n",
    "fit_and_predict_dados_reais(vencedor, treino_dados, treino_marcacoes, validacao_dados, validacao_marcacoes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
