{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from sklearn.naive_bayes import MultinomialNB      \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lendo o arquivo csv com o pandas\n",
    "df = pd.read_csv('./dados/site_alura.csv', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Separando as colunas do csv entre:\n",
    "X = Características do dados\n",
    "Y = Classificação das características \n",
    "\"\"\"\n",
    "\n",
    "X = df[[\"recencia\", \"frequencia\", \"semanas\"]]\n",
    "Y = df[\"situacao\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dummies = pd.get_dummies(X)\n",
    "X = X_dummies.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "porcentagem_treino = 0.8\n",
    "\n",
    "tamanho_treino = int(porcentagem_treino * len(X))\n",
    "\n",
    "treino_dados = X[0:tamanho_treino]\n",
    "treino_marcacoes = Y[0: tamanho_treino]\n",
    "\n",
    "validacao_dados = X[tamanho_treino:]\n",
    "validacao_marcacoes = Y[tamanho_treino:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho de treino:  180\n",
      "Tamanho de validação:  45\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamanho de treino: \", tamanho_treino)\n",
    "print(\"Tamanho de validação: \", tamanho_validacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contador:  Counter({1: 34, 0: 6, 2: 5})\n",
      "Taxa de acertos base: 75.56\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Verificando a acuracia do modelo, comparando com modelos burros\"\"\"\n",
    "\n",
    "contador = Counter(validacao_marcacoes)\n",
    "taxa_acerto_base = 100.0 * max(Counter(validacao_marcacoes).values())/len(validacao_marcacoes)\n",
    "\n",
    "print(\"Contador: \", contador)\n",
    "print(\"Taxa de acertos base: {:.2f}\" .format(taxa_acerto_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict(modelo, nome_algoritmo, treino_dados, treino_marcacoes):\n",
    "    \"\"\"\n",
    "        Treinando e predizendo o modelo\n",
    "        Verificando a acuracia do modelo\n",
    "        cross_val_score faz a quantidade de predições que forem colocadas no K e depois tira a média, é feito esse\n",
    "        tipo de abordagem para garantir que o resultado da predição não esta viciada devido ao posicionamento dos dados.\n",
    "    \"\"\"\n",
    "    k = 10\n",
    "\n",
    "    scores = cross_val_score(modelo, treino_dados, treino_marcacoes, cv = k)\n",
    "\n",
    "    taxa_media_acerto = np.mean(scores)\n",
    "                    \n",
    "    print(\"Média da taxa de acertos para o algoritmo {}, é de: {:.2f}\" .format(nome_algoritmo, taxa_media_acerto))\n",
    "    return taxa_media_acerto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict_dados_reais(modelo, treino_dados, treino_marcacoes, validacao_dados, validacao_marcacoes):\n",
    "    \"\"\"\n",
    "        Treinando e predizendo o modelo\n",
    "        Verificando a acuracia do modelo\n",
    "        resultado = São as inferências que o modelo predice tendo por base as caracteristicas dos dados passados \n",
    "    \"\"\"\n",
    "    modelo.fit(treino_dados, treino_marcacoes)\n",
    "    \n",
    "    resultado = modelo.predict(validacao_dados)\n",
    "\n",
    "    diferencas = (resultado == validacao_marcacoes)\n",
    "\n",
    "    acertos = sum(diferencas)\n",
    "    print(\"Taxa de acertos para algoritmo real, é de: {:.2f}\" .format(100 * (acertos / len(validacao_dados))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acertos base: 75.56\n",
      "Média da taxa de acertos para o algoritmo MultinomialNB, é de: 0.83\n",
      "Média da taxa de acertos para o algoritmo AdaBoostClassifier, é de: 0.76\n",
      "Média da taxa de acertos para o algoritmo OneVersusRest, é de: 0.93\n",
      "Média da taxa de acertos para o algoritmo OneVersusOne, é de: 0.99\n",
      "Taxa de acertos para algoritmo real, é de: 100.00\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Criando quatro modelos: MultinomialNB, AdaBoostClassifier, OneVersusRest, OneVersusOne\n",
    "\n",
    "Obs.: De maneira geral a previsão dos algoritmos funcionam identificando e classificando os elementos por meio\n",
    "das características que foram passadas no treinamento.\n",
    "Obs.1: Se a performance não for problema o algoritmo OneVersusOne deve ser executado.\n",
    "\"\"\"\n",
    "resultados = {}\n",
    "print(\"Taxa de acertos base: {:.2f}\" .format(taxa_acerto_base))\n",
    "\n",
    "modelo_multinomial = MultinomialNB()\n",
    "resultado_multinomial = fit_and_predict(modelo_multinomial, \"MultinomialNB\", treino_dados, treino_marcacoes)\n",
    "resultados[resultado_multinomial] = modelo_multinomial\n",
    "\n",
    "modelo_adaBoostClassifier = AdaBoostClassifier()\n",
    "resultado_adaboost = fit_and_predict(modelo_adaBoostClassifier, \"AdaBoostClassifier\", treino_dados, treino_marcacoes)\n",
    "resultados[resultado_adaboost] = modelo_adaBoostClassifier\n",
    "\n",
    "modelo_oneVersusRest = OneVsRestClassifier(LinearSVC(random_state=0))\n",
    "resultado_oneVersusRest = fit_and_predict(modelo_oneVersusRest, \"OneVersusRest\", treino_dados, treino_marcacoes)                                         \n",
    "resultados[resultado_oneVersusRest] = modelo_oneVersusRest\n",
    "\n",
    "modelo_OneVersusOne = OneVsOneClassifier(LinearSVC(random_state=0))\n",
    "resultado_OneVersusOne = fit_and_predict(modelo_OneVersusOne, \"OneVersusOne\", treino_dados, treino_marcacoes)\n",
    "resultados[resultado_OneVersusOne] = modelo_OneVersusOne\n",
    "\n",
    "vencedor = resultados[max(resultados)]\n",
    "fit_and_predict_dados_reais(vencedor, treino_dados, treino_marcacoes, validacao_dados, validacao_marcacoes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
